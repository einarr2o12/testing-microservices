# OpenTelemetry Collector DaemonSet for Infrastructure Metrics
# Collects node, container, and Kubernetes metrics

mode: daemonset

image:
  repository: otel/opentelemetry-collector-contrib
  tag: "0.87.0"

# Resource limits for infrastructure monitoring
resources:
  limits:
    cpu: 200m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Service account permissions for Kubernetes metrics
serviceAccount:
  create: true
  name: otel-collector-metrics

# Cluster role for accessing Kubernetes API
clusterRole:
  create: true
  rules:
    - apiGroups: [""]
      resources: ["nodes", "nodes/proxy", "nodes/metrics", "services", "endpoints", "pods"]
      verbs: ["get", "list", "watch"]
    - apiGroups: ["extensions", "apps"]
      resources: ["daemonsets", "deployments", "replicasets"]
      verbs: ["get", "list", "watch"]
    - nonResourceURLs: ["/metrics"]
      verbs: ["get"]

config:
  receivers:
    # Host/Node metrics (CPU, memory, disk, network)
    hostmetrics:
      collection_interval: 30s
      scrapers:
        cpu: {}
        memory: {}
        disk: {}
        network: {}
        filesystem: {}
        load: {}

    # Container and Pod metrics via kubelet
    kubeletstats:
      collection_interval: 30s
      auth_type: "serviceAccount"
      endpoint: "${env:KUBE_NODE_NAME}:10250"
      insecure_skip_verify: true

    # Kubernetes cluster state metrics
    k8s_cluster:
      auth_type: serviceAccount
      collection_interval: 30s
      node_conditions_to_report: [Ready, MemoryPressure, DiskPressure, PIDPressure]
      allocatable_types_to_report: [cpu, memory, storage]

  processors:
    # Add Kubernetes metadata
    k8sattributes:
      auth_type: "serviceAccount"
      passthrough: false
      extract:
        metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
      pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection

    # Memory limiter
    memory_limiter:
      check_interval: 1s
      limit_mib: 200
      spike_limit_mib: 50

    # Batch processor
    batch:
      timeout: 10s
      send_batch_size: 1024

    # Resource processor to add cluster info
    resource:
      attributes:
        - key: cluster.name
          value: "k8s-microservices"
          action: insert
        - key: environment
          value: "demo"
          action: insert

  exporters:
    # Prometheus metrics exporter
    prometheus:
      endpoint: "0.0.0.0:8889"
      metric_expiration: 180m
      enable_open_metrics: true

    # Debug exporter for troubleshooting
    debug:
      verbosity: basic

  service:
    pipelines:
      metrics:
        receivers: [hostmetrics, kubeletstats, k8s_cluster]
        processors: [k8sattributes, resource, memory_limiter, batch]
        exporters: [prometheus, debug]

# DaemonSet specific configuration
extraEnvs:
  - name: KUBE_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

extraVolumes:
  - name: hostfs
    hostPath:
      path: /
  - name: procfs
    hostPath:
      path: /proc
  - name: sysfs
    hostPath:
      path: /sys

extraVolumeMounts:
  - name: hostfs
    mountPath: /hostfs
    readOnly: true
  - name: procfs
    mountPath: /host/proc
    readOnly: true
  - name: sysfs
    mountPath: /host/sys
    readOnly: true

# Host network and tolerations
hostNetwork: true

tolerations:
  - operator: Exists
    effect: NoSchedule
  - operator: Exists
    effect: NoExecute

# Pod annotations
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8889"
  prometheus.io/path: "/metrics"